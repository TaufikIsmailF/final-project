# -*- coding: utf-8 -*-
"""Taufik Ismail Fadillah - Progress Script Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iGuXNlj9TAWrXKV6z-qHMoYyl4TdGiM2

**Objective:** Tujuan dari proyek ini adalah membangun model prediksi yang dapat menilai kemungkinan seseorang terkena kanker paru-paru berdasarkan berbagai kebiasaan hidup, gejala, dan informasi demografis. Dengan menganalisis fitur yang ada dalam dataset, seperti kebiasaan merokok, gejala-gejala seperti batuk atau nyeri dada, serta faktor demografis seperti usia dan jenis kelamin, kita ingin mengembangkan model yang dapat memprediksi risiko kanker paru-paru dengan akurat. Model tersebut nantinya bisa membantu deteksi dini, yang sangat penting untuk meningkatkan peluang kesembuhan kanker paru-paru melalui penanganan medis yang lebih cepat.

**Background:** Kanker paru-paru merupakan salah satu penyebab utama kematian akibat kanker di seluruh dunia. Deteksi dini sangat penting untuk meningkatkan peluang hidup, namun mengenali siapa saja yang berisiko bisa menjadi tantangan. Faktor-faktor seperti kebiasaan merokok, penyakit kronis, kecemasan, dan gejala yang sering dikaitkan dengan kanker paru-paru (seperti batuk, sesak napas, atau nyeri dada) memiliki peran penting dalam menilai risiko. Namun, faktor-faktor ini saja tidak cukup untuk memberikan kepastian, sehingga dibutuhkan model prediksi yang lebih canggih untuk menilai risiko kanker paru-paru dengan lebih tepat.

Dataset Risiko Kanker Paru-paru menyediakan kumpulan data yang meliputi informasi demografis (seperti usia, jenis kelamin), indikator gaya hidup (seperti kebiasaan merokok dan konsumsi alkohol), serta gejala medis (seperti batuk, nyeri dada). Dengan menganalisis dataset ini, kami berupaya mengidentifikasi fitur-fitur yang paling berdampak pada risiko kanker paru-paru dan mengembangkan model machine learning yang bisa memprediksi kemungkinan seseorang didiagnosis dengan kanker paru-paru.
"""

# Import libraries
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    balanced_accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score
)
from yellowbrick.classifier import ClassificationReport, ROCAUC

# Import library yang dibutuhkan
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler

# Membaca dataset
df = pd.read_csv('lungcancer.csv')

# Pisahkan fitur (X) dan target (y)
X = df.drop('LUNG_CANCER', axis=1)  # Fitur
y = df['LUNG_CANCER']  # Target

"""## Preliminary Look and Data Cleansing

### Sample of data
"""

df.info()

"""## General Information & Missing Values"""

df.describe()

# number of missing values per column
df.isna().sum()

"""## Duplicated data check"""

# number of duplicated data
df.duplicated().sum()

# Menghilangkan baris yang duplikat secara keseluruhan
df = df.drop_duplicates()

# Mengecek kembali data duplikat
df.duplicated().sum()

"""# EDA

# Data understanding

## Statistical summary
"""

from sklearn.preprocessing import LabelEncoder

# Mengubah variabel kategorikal menjadi numerik menggunakan Label Encoding
label_encoder = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = label_encoder.fit_transform(df[column])

# Memeriksa data setelah encoding
df.head()

"""**Description Columns:**

**GENDER:** The gender of the individual (e.g., M for male, F for female).

**AGE:** The age of the individual in years.

**SMOKING:** Indicates whether the individual is a smoker (Yes/No).

**YELLOW_FINGERS:** Indicates whether the individual has yellow fingers (Yes/No).

**ANXIETY:** Indicates whether the individual suffers from anxiety (Yes/No).

**PEER_PRESSURE:** Indicates whether the individual is influenced by peer pressure (Yes/No).

**CHRONIC_DISEASE:** Indicates whether the individual has any chronic disease (Yes/No).

**FATIGUE:** Indicates whether the individual experiences fatigue (Yes/No).

**ALLERGY:** Indicates whether the individual has allergies (Yes/No).

**WHEEZING:** Indicates whether the individual has wheezing symptoms (Yes/No).

**ALCOHOL_CONSUMING:** Indicates whether the individual consumes alcohol (Yes/No).

**COUGHING:** Indicates whether the individual has a coughing symptom (Yes/No).

**SHORTNESS_OF_BREATH:** Indicates whether the individual experiences shortness of breath (Yes/No).

***SWALLOWING_DIFFICULTY: ***Indicates whether the individual has difficulty swallowing (Yes/No).

**CHEST_PAIN:** Indicates whether the individual experiences chest pain (Yes/No).

**LUNG_CANCER:** Indicates whether the individual has been diagnosed with lung cancer (Yes/No).

"""

df.info()

# numerical statistical sumary
df.describe()

"""Interpretasi
1. **Mean** untuk kebanyakan fitur berada di sekitar 0.5, yang menunjukkan dataset yang relatif seimbang antara dua kelompok (contoh: antara yang mengalami gejala/kondisi dan yang tidak).

2. Berdasarkan **mean** dan **median**, tampaknya ada keseimbangan antara kelompok individu dengan kondisi kesehatan buruk dan sehat (misalnya, merokok, gejala fisik, dan kanker paru).

3. Fitur dengan **median dengan nilai 1** menunjukkan bahwa lebih dari separuh individu dalam dataset memiliki gejala atau kondisi tersebut (seperti merokok, kecemasan, sesak napas, kelelahan, dll).

## Data Cleaning Outlier Handling
"""

# boxplot untuk melihat sebelum outlier handling
plt.figure(figsize=(12, 6))
sns.boxplot(x=df['LUNG_CANCER'])
plt.title('Box Plot of LungCancer')
plt.xlabel('LUNGCANCER')
plt.show()

# outlier checking
Q1 = df['LUNG_CANCER'].quantile(0.25)
Q3 = df['LUNG_CANCER'].quantile(0.75)
IQR = Q3 - Q1
outliers = (df['LUNG_CANCER'] < (Q1 - 1.5 * IQR)) | (df['LUNG_CANCER'] > (Q3 + 1.5 * IQR))
print(f'Number of outliers based on IQR: {sum(outliers)}')

# Deteksi outlier untuk setiap kolom numerik
# Menghitung Q1, Q3, dan IQR untuk semua kolom
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

# Deteksi outlier: nilai yang berada di luar rentang [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
outliers = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))

# Menampilkan outlier
outliers_df = df[outliers.any(axis=1)]
print("Outliers in any column:")
print(outliers_df)

import matplotlib.pyplot as plt
import seaborn as sns

# Visualisasi outlier dengan boxplot
plt.figure(figsize=(40, 15))
sns.boxplot(data=df)
plt.show()

"""# Deep Dive EDA"""

import seaborn as sns
import matplotlib.pyplot as plt

# Plot jumlah 'PEER_PRESSURE' terhadap 'LUNG_CANCER'
plt.figure(figsize=(8,6))
sns.countplot(data=df, x='PEER_PRESSURE', hue='LUNG_CANCER')

# Menambahkan judul dan label yang lebih jelas
plt.title('Pengaruh Peer Pressure terhadap Kasus Kanker Paru-paru', fontsize=16)
plt.xlabel('Peer Pressure (0: Tidak, 1: Ya)', fontsize=14)
plt.ylabel('Jumlah Kasus', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.legend(title='Lung Cancer', fontsize=12, title_fontsize='13')

plt.tight_layout()
plt.show()

# pairplot of the data
sns.pairplot(df, hue='LUNG_CANCER')

"""Interpretasi:

Jumlah Sampel: Kelas 0 memiliki 438 sampel dan kelas 1 memiliki 462 sampel, menunjukkan distribusi yang cukup seimbang. Oleh karena itu, isu imbalance kelas kemungkinan tidak menjadi penyebab utama rendahnya performa model.
"""

# Heatmap corelation

plt.figure(figsize=(20, 20))  # Atur ukuran gambar agar lebih proporsional
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm',
            cbar_kws={'shrink': .8})  # `shrink` untuk menyesuaikan ukuran colorbar
plt.xticks(rotation=45, ha='right', fontsize=10)  # Merotasi dan menyesuaikan font label X
plt.yticks(rotation=0, fontsize=10)  # Menyesuaikan font label Y
plt.title('Matriks Korelasi', fontsize=16)
plt.tight_layout()  # Menyesuaikan layout agar label tidak terpotong
plt.show()

# distribusi data LUNG_CANCER (before outlier handling)
plt.figure(figsize=(12, 6))
sns.histplot(df['LUNG_CANCER'], kde=True)
plt.title('Distribution of LUNG CANCER')
plt.xlabel('LUNG_CANCER')
plt.ylabel('Frequency')
plt.show()

# boxplot untuk melihat outlier
plt.figure(figsize=(12, 6))
sns.boxplot(x=df['LUNG_CANCER'])
plt.title('Box Plot of LUNG_CANCER')
plt.xlabel('LUNG CANCER')
plt.show()

#Prediksi LUNG_CANCER pada setiap Kolom fitur yang menunjukan kata "YES"

for feature in df.columns:
    if feature not in ['LUNG_CANCER', 'AGE']:
        total_count = df[df[feature] == 1].shape[0]
        lung_cancer_count = df[(df[feature] == 1) & (df['LUNG_CANCER'] == 1)].shape[0]
        percentage = (lung_cancer_count / total_count) * 100 if total_count != 0 else 0
        print(f"'{feature}': {lung_cancer_count}/ {total_count} = {percentage:.2f}%")

import matplotlib.pyplot as plt
import seaborn as sns

# Data untuk visualisasi Prediksi LUNG_CANCER pada setiap Kolom fitur yang menunjukan kata "YES"
features = []
percentages = []

for feature in df.columns:
    if feature not in ['LUNG_CANCER', 'AGE']:
        total_count = df[df[feature] == 1].shape[0]
        lung_cancer_count = df[(df[feature] == 1) & (df['LUNG_CANCER'] == 1)].shape[0]
        percentage = (lung_cancer_count / total_count) * 100 if total_count != 0 else 0
        features.append(feature)
        percentages.append(percentage)

# Membuat bar plot
plt.figure(figsize=(10, 6))
sns.barplot(x=percentages, y=features, palette='Blues_d')

# Menambahkan label dan judul
plt.xlabel('Percentage of Lung Cancer Cases (%)')
plt.ylabel('Features with YES Response')
plt.title('Percentage of Lung Cancer Cases for Each Feature with YES Response')
plt.xlim(0, 100)  # Batas sumbu x untuk lebih jelas
plt.tight_layout()

# Menampilkan plot
plt.show()

"""interpretasi:
1. Faktor seperti smoking, wheezing, chronic disease, peer pressure, dan alcohol consuming menunjukkan hubungan yang lebih signifikan dengan kanker paru-paru, di mana lebih dari 50% kasus menunjukkan nilai "YES".

2. Gejala fisik seperti yellow fingers, shortness of breath, dan coughing juga berkontribusi sebagai tanda-tanda umum pada penderita kanker paru-paru.

3. Fitur dengan persentase sekitar 50% menunjukkan bahwa faktor-faktor tersebut mungkin relevan untuk kanker paru-paru, tetapi faktor lain (seperti perilaku dan riwayat medis) juga perlu diperhitungkan.
"""

#Prediksi LUNG_CANCER pada setiap Kolom fitur yang menunjukan kata "NO"

for feature in df.columns:
    if feature not in ['LUNG_CANCER', 'AGE']:
        total_count = df[df[feature] == 0].shape[0]
        lung_cancer_count = df[(df[feature] == 0) & (df['LUNG_CANCER'] == 1)].shape[0]
        percentage = (lung_cancer_count / total_count) * 100 if total_count != 0 else 0
        print(f"'{feature}': {lung_cancer_count}/ {total_count} = {percentage:.2f}%")

import matplotlib.pyplot as plt
import seaborn as sns

# Data untuk visualisasi
features_no = []
percentages_no = []

for feature in df.columns:
    if feature not in ['LUNG_CANCER', 'AGE']:
        total_count = df[df[feature] == 0].shape[0]
        lung_cancer_count = df[(df[feature] == 0) & (df['LUNG_CANCER'] == 1)].shape[0]
        percentage = (lung_cancer_count / total_count) * 100 if total_count != 0 else 0
        features_no.append(feature)
        percentages_no.append(percentage)

# Membuat bar plot untuk fitur yang menunjukkan "NO"
plt.figure(figsize=(10, 6))
sns.barplot(x=percentages_no, y=features_no, palette='Reds_d')

# Menambahkan label dan judul
plt.xlabel('Percentage of Lung Cancer Cases (%)')
plt.ylabel('Features with NO Response')
plt.title('Percentage of Lung Cancer Cases for Each Feature with NO Response')
plt.xlim(0, 100)  # Batas sumbu x untuk lebih jelas
plt.tight_layout()

# Menampilkan plot
plt.show()

"""Interpretasi:


Pada deep dive EDA disini hanya ada data untuk jenis kelamin 'F' (perempuan).

Beberapa fitur yang unik terlihat:


1. COUGHING (Batuk) dengan persentase 52,22% merupakan faktor yang paling tinggi di antara orang-orang yang tidak memiliki kanker paru-paru. Ini menunjukkan bahwa batuk bisa menjadi indikator penting dalam prediksi kanker paru-paru.

2. WHEEZING (Mengi) memiliki nilai persentase terendah di 48,66%, menunjukkan bahwa mengi mungkin lebih terkait dengan kasus orang yang menderita kanker paru-paru.

Fitur-fitur lainnya, seperti GENDER, SMOKING, dan ALLERGY, memiliki persentase sedikit di atas atau di bawah 50%, menunjukkan bahwa meskipun ada hubungan, faktor-faktor ini tidak memberikan diferensiasi yang sangat signifikan.

## Building Model
"""

# data splitting
X = df.drop(columns=['LUNG_CANCER'])
y = df['LUNG_CANCER']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)

from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier


# Pipeline untuk DecisionTreeClassifier
pipeline_dtc = Pipeline([
    ('model', DecisionTreeClassifier(random_state=42))
])

# Pipeline untuk XGBoost Classifier
pipeline_xgbc = Pipeline([
    ('model', XGBClassifier(random_state=42))
])

# Pipeline untuk LightGBM Classifier
pipeline_lgbmc = Pipeline([
    ('model', LGBMClassifier(random_state=42))
])

# Pipeline untuk HistGradientBoostingClassifier
pipeline_hgbc = Pipeline([
    ('model', HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, max_depth=3))
])

pipeline_rf = Pipeline([
    ('model', RandomForestClassifier())
])

"""### Hyperparameter Tuning"""

from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# Parameter grid untuk DecisionTreeClassifier
param_grid_dtc = {
    'model__max_depth': [None, 10, 20, 30],
    'model__min_samples_split': [2, 5, 10],
    'model__min_samples_leaf': [1, 2, 4],
    'model__criterion': ['gini', 'entropy']
}

# Parameter grid untuk XGBClassifier
param_grid_xgbc = {
    'model__n_estimators': [100, 200, 300],
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__max_depth': [3, 5, 7],
    'model__subsample': [0.6, 0.8, 1.0]
}

# Parameter grid untuk LGBMClassifier
param_grid_lgbmc = {
    'model__n_estimators': [100, 200, 300],
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__max_depth': [3, 5, 7],
    'model__num_leaves': [20, 30, 40]
}

# Parameter grid untuk HistGradientBoostingClassifier
param_grid_hgbc = {
    'model__max_iter': [100, 200],
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__max_depth': [3, 5, 7]
}

# Parameter grid untuk RandomForest
param_grid_rf = {
    'model__n_estimators': [100, 200, 300, 400, 500],  # Jumlah pohon dalam hutan
    'model__max_depth': [None, 10, 20, 30, 40, 50],  # Kedalaman maksimum pohon
    'model__min_samples_split': [2, 5, 10],  # Jumlah sampel minimum untuk membagi node
    'model__min_samples_leaf': [1, 2, 4],  # Jumlah sampel minimum per daun
    'model__bootstrap': [True, False]  # Jika menggunakan bootstrap sampling
}


# Pipeline untuk setiap model
pipeline_dtc = Pipeline([('model', DecisionTreeClassifier())])
pipeline_xgbc = Pipeline([('model', XGBClassifier())])
pipeline_lgbmc = Pipeline([('model', LGBMClassifier())])
pipeline_hgbc = Pipeline([('model', HistGradientBoostingClassifier())])
pipeline_rf = Pipeline([('model', RandomForestClassifier())])

# Randomized Search untuk masing-masing model
random_search_dtc = RandomizedSearchCV(
    pipeline_dtc,
    param_distributions=param_grid_dtc,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

random_search_xgbc = RandomizedSearchCV(
    pipeline_xgbc,
    param_distributions=param_grid_xgbc,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

random_search_lgbmc = RandomizedSearchCV(
    pipeline_lgbmc,
    param_distributions=param_grid_lgbmc,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

random_search_hgbc = RandomizedSearchCV(
    pipeline_hgbc,
    param_distributions=param_grid_hgbc,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

random_search_rf = RandomizedSearchCV(
    pipeline_rf,
    param_distributions=param_grid_rf,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

# Fit semua model
random_search_dtc.fit(X_train, y_train)
random_search_xgbc.fit(X_train, y_train)
random_search_lgbmc.fit(X_train, y_train)
random_search_hgbc.fit(X_train, y_train)
random_search_rf.fit(X_train, y_train)

# Best estimators
best_dtc = random_search_dtc.best_estimator_
best_xgbc = random_search_xgbc.best_estimator_
best_lgbmc = random_search_lgbmc.best_estimator_
best_hgbc = random_search_hgbc.best_estimator_
best_rf = random_search_rf.best_estimator_

# Print best parameters
print("Best parameters for DecisionTreeClassifier:", random_search_dtc.best_params_)
print("Best parameters for XGBClassifier:", random_search_xgbc.best_params_)
print("Best parameters for LGBMClassifier:", random_search_lgbmc.best_params_)
print("Best parameters for HistGradientBoostingClassifier:", random_search_hgbc.best_params_)
print("Best parameters for RandomForestClassifier:", random_search_rf.best_params_)

"""## Evaluation Metrics"""

from sklearn.metrics import confusion_matrix

# Predict
y_pred_dtc = best_dtc.predict(X_test)
y_pred_xgbc = best_xgbc.predict(X_test)
y_pred_lgbmc = best_lgbmc.predict(X_test)
y_pred_hgbc = best_hgbc.predict(X_test)
y_pred_rf = best_rf.predict(X_test)

# Evaluation metrics for Decision Tree Classifier
accuracy_dtc = accuracy_score(y_test, y_pred_dtc)
precision_dtc = precision_score(y_test, y_pred_dtc, average='micro')
recall_dtc = recall_score(y_test, y_pred_dtc, average='micro')
f1_dtc = f1_score(y_test, y_pred_dtc, average='micro')
cm_dtc = confusion_matrix(y_test, y_pred_dtc)

print(f'Decision Tree Classifier Accuracy: {accuracy_dtc:.2f}')
print(f'Decision Tree Classifier Precision: {precision_dtc:.2f}')
print(f'Decision Tree Classifier Recall: {recall_dtc:.2f}')
print(f'Decision Tree Classifier F1-Score: {f1_dtc:.2f}')
print(f'Decision Tree Classifier Confusion Matrix:\n{cm_dtc}')
print(f'Decision Tree Classifier Classification Report:\n{classification_report(y_test, y_pred_dtc)}')

# Evaluation metrics for XGBoost Classifier
accuracy_xgbc = accuracy_score(y_test, y_pred_xgbc)
precision_xgbc = precision_score(y_test, y_pred_xgbc, average='micro')
recall_xgbc = recall_score(y_test, y_pred_xgbc, average='micro')
f1_xgbc = f1_score(y_test, y_pred_xgbc, average='micro')
cm_xgbc = confusion_matrix(y_test, y_pred_xgbc)

print(f'XGBoost Classifier Accuracy: {accuracy_xgbc:.2f}')
print(f'XGBoost Classifier Precision: {precision_xgbc:.2f}')
print(f'XGBoost Classifier Recall: {recall_xgbc:.2f}')
print(f'XGBoost Classifier F1-Score: {f1_xgbc:.2f}')
print(f'XGBoost Classifier Confusion Matrix:\n{cm_xgbc}')
print(f'XGBoost Classifier Classification Report:\n{classification_report(y_test, y_pred_xgbc)}')

# Evaluation metrics for LightGBM Classifier
accuracy_lgbmc = accuracy_score(y_test, y_pred_lgbmc)
precision_lgbmc = precision_score(y_test, y_pred_lgbmc, average='micro')
recall_lgbmc = recall_score(y_test, y_pred_lgbmc, average='micro')
f1_lgbmc = f1_score(y_test, y_pred_lgbmc, average='micro')
cm_lgbmc = confusion_matrix(y_test, y_pred_lgbmc)

print(f'LightGBM Classifier Accuracy: {accuracy_lgbmc:.2f}')
print(f'LightGBM Classifier Precision: {precision_lgbmc:.2f}')
print(f'LightGBM Classifier Recall: {recall_lgbmc:.2f}')
print(f'LightGBM Classifier F1-Score: {f1_lgbmc:.2f}')
print(f'LightGBM Classifier Confusion Matrix:\n{cm_lgbmc}')
print(f'LightGBM Classifier Classification Report:\n{classification_report(y_test, y_pred_lgbmc)}')

# Evaluation metrics for HistGradientBoosting Classifier
accuracy_hgbc = accuracy_score(y_test, y_pred_hgbc)
precision_hgbc = precision_score(y_test, y_pred_hgbc, average='micro')
recall_hgbc = recall_score(y_test, y_pred_hgbc, average='micro')
f1_hgbc = f1_score(y_test, y_pred_hgbc, average='micro')
cm_hgbc = confusion_matrix(y_test, y_pred_hgbc)

print(f'HistGradientBoosting Classifier Accuracy: {accuracy_hgbc:.2f}')
print(f'HistGradientBoosting Classifier Precision: {precision_hgbc:.2f}')
print(f'HistGradientBoosting Classifier Recall: {recall_hgbc:.2f}')
print(f'HistGradientBoosting Classifier F1-Score: {f1_hgbc:.2f}')
print(f'HistGradientBoosting Classifier Confusion Matrix:\n{cm_hgbc}')
print(f'HistGradientBoosting Classifier Classification Report:\n{classification_report(y_test, y_pred_hgbc)}')

# Evaluation metrics for RandomForest Classifier
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf, average='micro')
recall_rf = recall_score(y_test, y_pred_rf, average='micro')
f1_rf = f1_score(y_test, y_pred_rf, average='micro')
cm_rf = confusion_matrix(y_test, y_pred_rf)

print(f'RandomForest Classifier Accuracy: {accuracy_rf:.2f}')
print(f'RandomForest Classifier Precision: {precision_rf:.2f}')
print(f'RandomForest Classifier Recall: {recall_rf:.2f}')
print(f'RandomForest Classifier F1-Score: {f1_rf:.2f}')
print(f'RandomForest Classifier Confusion Matrix:\n{cm_rf}')
print(f'RandomForest Classifier Classification Report:\n{classification_report(y_test, y_pred_rf)}')

"""Dari hasil evaluasi yang diberikan, semua model memiliki kinerja yang cukup mirip dengan akurasi di sekitar 0.53 hingga 0.54. Namun, untuk menentukan model mana yang paling baik dalam memprediksi kanker paru, kita perlu melihat lebih jauh pada metrik-metrik evaluasi lainnya seperti Precision, Recall, dan F1-Score, terutama pada masing-masing kelas (positif dan negatif) serta matriks kebingungan (confusion matrix). Berikut analisis lebih lanjut:

**Accuracy:**

Semua model memiliki akurasi yang mirip, antara 0.53 dan 0.54. Ini menunjukkan bahwa tidak ada model yang jauh lebih baik dari yang lain dalam hal ini.

**Precision:**

Precision untuk kelas positif (1) pada model LightGBM (0.55) sedikit lebih tinggi dibandingkan model lainnya. Precision menunjukkan seberapa banyak dari prediksi positif yang benar-benar positif, yang penting jika kita ingin meminimalisir prediksi positif palsu.

**Recall:**

Recall untuk kelas positif (1) juga paling tinggi pada model LightGBM (0.55), artinya model ini mampu mendeteksi lebih banyak kasus kanker paru dibanding model lainnya.

**F1-Score:**

F1-Score untuk kelas positif (1) lagi-lagi lebih tinggi pada model LightGBM (0.55), yang merupakan trade-off antara Precision dan Recall. Hal ini menunjukkan keseimbangan yang lebih baik antara kedua metrik tersebut.

**Confusion Matrix:**

**Model LightGBM** memiliki distribusi yang cukup seimbang dalam mendeteksi kedua kelas (0 dan 1), dengan jumlah true positive (252) dan true negative (232) yang lebih tinggi dibandingkan beberapa model lainnya. Ini menunjukkan kemampuan model untuk memprediksi kedua kelas dengan lebih baik.

**Kesimpulan:**

Meskipun perbedaan antar model tidak terlalu besar, LightGBM menunjukkan kinerja yang sedikit lebih baik dibandingkan model lainnya berdasarkan F1-Score, Precision, dan Recall untuk kelas positif (1). Ini menjadikannya pilihan yang lebih baik jika tujuan utama adalah untuk mendeteksi kasus kanker paru dengan keseimbangan antara mengurangi false positives dan meningkatkan detection rate.

# Conclusion Best Model for Result
"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Setup figure and axes
fig, axs = plt.subplots(1, 5, figsize=(25, 5))  # 1 baris, 5 kolom

# Visualisasi Confusion matrix pada model Decision Tree Classifier
cm_dtc = confusion_matrix(y_test, y_pred_dtc)
sns.heatmap(cm_dtc, annot=True, fmt='d', cmap='Blues', ax=axs[0])
axs[0].set_title('Decision Tree Classifier')
axs[0].set_xlabel('Predicted')
axs[0].set_ylabel('Actual')

# Visualisasi  Confusion matrix pada model XGBoost Classifier
cm_xgbc = confusion_matrix(y_test, y_pred_xgbc)
sns.heatmap(cm_xgbc, annot=True, fmt='d', cmap='Greens', ax=axs[1])
axs[1].set_title('XGBoost Classifier')
axs[1].set_xlabel('Predicted')
axs[1].set_ylabel('Actual')

# Visualisasi Confusion matrix pada model LightGBM Classifier
cm_lgbmc = confusion_matrix(y_test, y_pred_lgbmc)
sns.heatmap(cm_lgbmc, annot=True, fmt='d', cmap='Blues', ax=axs[2])
axs[2].set_title('LightGBM Classifier')
axs[2].set_xlabel('Predicted')
axs[2].set_ylabel('Actual')

# Visualisasi Confusion matrix pada model HistGradientBoosting Classifier
cm_hgbc = confusion_matrix(y_test, y_pred_hgbc)
sns.heatmap(cm_hgbc, annot=True, fmt='d', cmap='Oranges', ax=axs[3])
axs[3].set_title('HistGradientBoosting Classifier')
axs[3].set_xlabel('Predicted')
axs[3].set_ylabel('Actual')

# Visualisasi Confusion matrix pada model RandomForest Classifier
cm_rf = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Reds', ax=axs[4])
axs[4].set_title('RandomForest Classifier')
axs[4].set_xlabel('Predicted')
axs[4].set_ylabel('Actual')

# Adjust layout
plt.tight_layout()
plt.show()

"""Interpretasi:

Dari analisis ini, jika tujuan utama adalah untuk mendeteksi kasus kanker paru dengan tepat, maka **Random Forest** adalah model yang paling baik karena memiliki **True Positives** tertinggi. Namun, jika menginginkan model yang meminimalisir **false positives**, maka **Decision Tree** bisa jadi pilihan yang lebih baik.

Makna dari Confusion Matrix Terhadap Kanker Paru:

**1. Kesalahan FP (False Positive):**

  Pasien yang sebenarnya sehat bisa mengalami kecemasan dan mungkin menjalani tes lanjutan yang tidak perlu.
Dalam konteks klinis, FP masih dapat diterima jika dibandingkan dengan FN, tetapi tetap harus diminimalisir.

**2. Kesalahan FN (False Negative):**

  Pasien yang sebenarnya menderita kanker paru tidak akan terdeteksi dan mungkin tidak mendapatkan perawatan yang dibutuhkan tepat waktu.
Ini adalah jenis kesalahan yang paling kritis dalam konteks medis, karena berpotensi membahayakan kesehatan dan keselamatan pasien.
"""

